{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🐜🐜워크맨 인력소🐜🐜\\r\\n워크맨의 리뷰를 원하는 job것이 있다면↓댓글 추천↓\\r...</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>7101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쿠팡상하차</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>야구장 치어리더</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV 배우</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임상실험 알바 해주세요!!!!</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>아나운서였오 미친ㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>똘끼 쩌네요 ㅋ\\n편집점이 이렇게 나오게 하는건지</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>아침마다 날씨로 뵙는분인데 이렇게 웃기신 분일줄이얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>저슬 쭈물러욬ㅋㅋㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>이누나 ㄹㅇ 취저네ㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10409 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review   date  like\n",
       "0     🐜🐜워크맨 인력소🐜🐜\\r\\n워크맨의 리뷰를 원하는 job것이 있다면↓댓글 추천↓\\r...   1년 전  7101\n",
       "1                                                 쿠팡상하차   1년 전  1055\n",
       "2                                              야구장 치어리더   1년 전   823\n",
       "3                                                 AV 배우   1년 전   627\n",
       "4                                      임상실험 알바 해주세요!!!!   1년 전   223\n",
       "...                                                 ...    ...   ...\n",
       "3679                                       아나운서였오 미친ㅋㅋㅋ  6개월 전     0\n",
       "3680                        똘끼 쩌네요 ㅋ\\n편집점이 이렇게 나오게 하는건지  6개월 전     1\n",
       "3681          아침마다 날씨로 뵙는분인데 이렇게 웃기신 분일줄이얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ  6개월 전     0\n",
       "3682                                       저슬 쭈물러욬ㅋㅋㅋㅋㅋ  6개월 전     0\n",
       "3683                                      이누나 ㄹㅇ 취저네ㅋㅋㅋ  6개월 전     0\n",
       "\n",
       "[10409 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding은 보통 utf-8, cp949 로 하면되지만 이번 파일은 latin1\n",
    "data = pd.read_csv('1.3만_워크맨_m8JrVquHNsY.csv', header = None, names = ['review','date','like'])\n",
    "data2 = pd.read_csv('1.6만_워크맨_UQYCWLrCUy4.csv', header = None, names = ['review','date','like'])\n",
    "data3 = pd.read_csv('2.4만_워크맨_BWROdI-AgAU.csv', header = None, names = ['review','date','like'])\n",
    "\n",
    "data_all = pd.concat([data,data2,data3])\n",
    "\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10409 entries, 0 to 3683\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  10409 non-null  object\n",
      " 1   date    10409 non-null  object\n",
      " 2   like    10409 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 325.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1년 전', '1년 전(수정됨)', '10개월 전', '9개월 전', '8개월 전', '7개월 전', '6개월 전',\n",
       "       '4개월 전', '4개월 전(수정됨)', '3개월 전', '2개월 전', '5개월 전(수정됨)', '2주 전',\n",
       "       '1주 전', '1개월 전', '4주 전', '9개월 전(수정됨)', '3주 전', '3주 전(수정됨)', '4일 전',\n",
       "       '34분 전', '30분 전', '5개월 전', '8개월 전(수정됨)', '3시간 전', '11개월 전',\n",
       "       '7개월 전(수정됨)', '14시간 전', '11개월 전(수정됨)', '1개월 전(수정됨)', '3개월 전(수정됨)',\n",
       "       '9시간 전', '2일 전', '10개월 전(수정됨)', '6개월 전(수정됨)', '3일 전', '2개월 전(수정됨)',\n",
       "       '1일 전', '6일 전', '5일 전', '16시간 전', '1주 전(수정됨)', '7시간 전',\n",
       "       '2주 전(수정됨)', '10시간 전', '8시간 전', '13시간 전', '2시간 전', '4일 전(수정됨)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.15621097127486"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.15621097127486\n"
     ]
    }
   ],
   "source": [
    "Mean = data_all['like'].mean()\n",
    "print(Mean)\n",
    "\n",
    "data_all.loc[data_all[\"like\"] < Mean, \"like\"] = 0\n",
    "data_all.loc[data_all[\"like\"] >= Mean, \"like\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9515\n",
       "1     894\n",
       "Name: like, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       🐜🐜워크맨 인력소🐜🐜\\r\\n워크맨의 리뷰를 원하는 job것이 있다면↓댓글 추천↓\\r...\n",
       "1                                                   쿠팡상하차\n",
       "2                                                야구장 치어리더\n",
       "3                                                   AV 배우\n",
       "4                                        임상실험 알바 해주세요!!!!\n",
       "                              ...                        \n",
       "3679                                         아나운서였오 미친ㅋㅋㅋ\n",
       "3680                          똘끼 쩌네요 ㅋ\\n편집점이 이렇게 나오게 하는건지\n",
       "3681            아침마다 날씨로 뵙는분인데 이렇게 웃기신 분일줄이얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
       "3682                                         저슬 쭈물러욬ㅋㅋㅋㅋㅋ\n",
       "3683                                        이누나 ㄹㅇ 취저네ㅋㅋㅋ\n",
       "Name: review, Length: 10409, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['review'] = data_all['review'].str.replace(\"[^\\w]\", \" \")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[0-9]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[a-z]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[A-Z]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.strip()\n",
    "data_all['review'] = data_all['review'].replace('', np.nan)\n",
    "data_all = data_all.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-5c6af552bb78>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"[^\\w]\", \" \")\n",
      "<ipython-input-10-5c6af552bb78>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"전\", \"\")\n",
      "<ipython-input-10-5c6af552bb78>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"개\", \"\")\n",
      "<ipython-input-10-5c6af552bb78>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "data_all['date'] = data_all['date'].str.replace(\"[^\\w]\", \" \")\n",
    "data_all['date'] = data_all['date'].str.replace(\"전\", \"\")\n",
    "data_all['date'] = data_all['date'].str.replace(\"개\", \"\")\n",
    "data_all['date'] = data_all['date'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all['review']=data_all[['review','date']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8968\n",
       "1     866\n",
       "Name: like, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "review_train, review_test,date_train, date_test, y_train, y_test = train_test_split(data_all['review'],data_all['date'], data_all['like'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "stopwords = ['이', '가', '을', '를','은','는','에','의','도']\n",
    "\n",
    "cnt = 0\n",
    "X_train = []\n",
    "for stc in review_train:\n",
    "    words = Okt().morphs(stc)\n",
    "    token = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_train.append(token)\n",
    "    \n",
    "X_test = []\n",
    "for stc in review_test:\n",
    "    words = Okt().morphs(stc)\n",
    "    token = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_test.append(token)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "X_train_2 = []\n",
    "for stc in date_train:\n",
    "    X_train_2.append(stc.split())\n",
    "    \n",
    "X_test_2 = []\n",
    "for stc in date_test:\n",
    "    X_test_2.append(stc.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7867\n",
      "1967\n",
      "7867\n",
      "1967\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_train_2))\n",
    "print(len(X_test_2))\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i]+=X_train_2[i]\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i]+=X_test_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_2 = []\n",
    "# for stc in date_train:\n",
    "#     X_train_2.append(stc.split())\n",
    "    \n",
    "# X_test_2 = []\n",
    "# for stc in date_test:\n",
    "#     X_test_2.append(stc.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# X_train 단어들을 토대로 정수 인덱스 설정\n",
    "# 빈도수가 높은 것부터 4000개만 정수 인덱스로 변환하겠다!\n",
    "tokenizer = Tokenizer(4000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 위에서 설정된 정수 인덱스를 토대로 변환\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "print('# int_encoding done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_2 = Tokenizer()\n",
    "# tokenizer_2.fit_on_texts(X_train_2)\n",
    "\n",
    "# X_train_2 = tokenizer_2.texts_to_sequences(X_train_2)\n",
    "# X_test_2 = tokenizer_2.texts_to_sequences(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13139\n",
      "8319\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.word_index))\n",
    "\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "    if word_count == 1:\n",
    "        low_count += 1\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for data in X_train:\n",
    "    if max_length < len(data):\n",
    "        max_length = len(data)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 40\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "# X_train_2 = pad_sequences(X_train_2, maxlen=2)\n",
    "# X_test_2 = pad_sequences(X_test_2, maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train : np.concatenate((X_train_2,X_train), axis=1)\n",
    "# X_test : np.concatenate((X_test_2,X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(4000, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 5회 이상 검증데이터 loss가 증가하면, 과적합될 수 있으므로 학습을 조기종료!\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# 훈련을 거듭하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트로 저장\n",
    "model_check = ModelCheckpoint('the_best.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246/246 [==============================] - 3s 10ms/step - loss: 0.2584 - acc: 0.9162 - val_loss: 0.2830 - val_acc: 0.8937\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 2s 10ms/step - loss: 0.2036 - acc: 0.9241 - val_loss: 0.2564 - val_acc: 0.8963\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 3s 11ms/step - loss: 0.1855 - acc: 0.9310 - val_loss: 0.2825 - val_acc: 0.8963\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 3s 12ms/step - loss: 0.1733 - acc: 0.9367 - val_loss: 0.2712 - val_acc: 0.9024\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 3s 14ms/step - loss: 0.1634 - acc: 0.9418 - val_loss: 0.2872 - val_acc: 0.9044\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 4s 15ms/step - loss: 0.1555 - acc: 0.9455 - val_loss: 0.2911 - val_acc: 0.9024\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 3s 13ms/step - loss: 0.1517 - acc: 0.9448 - val_loss: 0.2952 - val_acc: 0.9029\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 2s 9ms/step - loss: 0.1469 - acc: 0.9460 - val_loss: 0.3546 - val_acc: 0.8993\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1415 - acc: 0.9484 - val_loss: 0.3550 - val_acc: 0.9029\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1350 - acc: 0.9517 - val_loss: 0.3276 - val_acc: 0.9014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9d7dc0e80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3276 - acc: 0.9014\n",
      "[0.32758110761642456, 0.9013726711273193]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 진짜 이 편은 개인적으로 레전드다ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 선배님들도 그렇고 특히 미리 선배님이랑 점장님 센스 개 오지고 이때 장성규 입담 유독 내 스타일이기도 하고 개 웃기네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      " 1년\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    9   88  671   71\n",
      "    38  251   22  453  359   21  636 1784  359   21  149  478   39  697\n",
      "    52   49    6 1386   87 1510   64   39   91   40  826    1]]\n",
      "[[0.10060126]]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "sentence = input()\n",
    "date = input()\n",
    "\n",
    "# 토큰화\n",
    "sentence = sentence.replace(\"[^\\w]\", \" \")\n",
    "sentence = sentence.replace(\"[0-9]\", \"\")\n",
    "sentence = sentence.replace(\"[a-z]\", \"\")\n",
    "sentence = sentence.replace(\"[A-Z]\", \"\")\n",
    "sentence = sentence.strip()\n",
    "\n",
    "date = date.replace(\"[^\\w]\", \" \")\n",
    "date = date.replace(\"전\", \"\")\n",
    "date = date.replace(\"개\", \"\")\n",
    "date = date.strip()\n",
    "\n",
    "sentence+=date\n",
    "\n",
    "words = Okt().morphs(sentence)\n",
    "\n",
    "words_re = []\n",
    "for word in words:\n",
    "    if word not in stopwords:\n",
    "        words_re.append(word)\n",
    "\n",
    "encode_stc = tokenizer.texts_to_sequences([words_re])\n",
    "\n",
    "pad_stc = pad_sequences(encode_stc, maxlen = 40)\n",
    "print(pad_stc)\n",
    "print(model.predict(pad_stc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
