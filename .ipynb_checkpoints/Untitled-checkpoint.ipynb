{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸœğŸœì›Œí¬ë§¨ ì¸ë ¥ì†ŒğŸœğŸœ\\r\\nì›Œí¬ë§¨ì˜ ë¦¬ë·°ë¥¼ ì›í•˜ëŠ” jobê²ƒì´ ìˆë‹¤ë©´â†“ëŒ“ê¸€ ì¶”ì²œâ†“\\r...</td>\n",
       "      <td>1ë…„ ì „</td>\n",
       "      <td>7101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì¿ íŒ¡ìƒí•˜ì°¨</td>\n",
       "      <td>1ë…„ ì „</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì•¼êµ¬ì¥ ì¹˜ì–´ë¦¬ë”</td>\n",
       "      <td>1ë…„ ì „</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV ë°°ìš°</td>\n",
       "      <td>1ë…„ ì „</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì„ìƒì‹¤í—˜ ì•Œë°” í•´ì£¼ì„¸ìš”!!!!</td>\n",
       "      <td>1ë…„ ì „</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>ì•„ë‚˜ìš´ì„œì˜€ì˜¤ ë¯¸ì¹œã…‹ã…‹ã…‹</td>\n",
       "      <td>6ê°œì›” ì „</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>ë˜˜ë¼ ì©Œë„¤ìš” ã…‹\\ní¸ì§‘ì ì´ ì´ë ‡ê²Œ ë‚˜ì˜¤ê²Œ í•˜ëŠ”ê±´ì§€</td>\n",
       "      <td>6ê°œì›” ì „</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>ì•„ì¹¨ë§ˆë‹¤ ë‚ ì”¨ë¡œ ëµ™ëŠ”ë¶„ì¸ë° ì´ë ‡ê²Œ ì›ƒê¸°ì‹  ë¶„ì¼ì¤„ì´ì–”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹</td>\n",
       "      <td>6ê°œì›” ì „</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>ì €ìŠ¬ ì­ˆë¬¼ëŸ¬ìš¬ã…‹ã…‹ã…‹ã…‹ã…‹</td>\n",
       "      <td>6ê°œì›” ì „</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>ì´ëˆ„ë‚˜ ã„¹ã…‡ ì·¨ì €ë„¤ã…‹ã…‹ã…‹</td>\n",
       "      <td>6ê°œì›” ì „</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10409 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review   date  like\n",
       "0     ğŸœğŸœì›Œí¬ë§¨ ì¸ë ¥ì†ŒğŸœğŸœ\\r\\nì›Œí¬ë§¨ì˜ ë¦¬ë·°ë¥¼ ì›í•˜ëŠ” jobê²ƒì´ ìˆë‹¤ë©´â†“ëŒ“ê¸€ ì¶”ì²œâ†“\\r...   1ë…„ ì „  7101\n",
       "1                                                 ì¿ íŒ¡ìƒí•˜ì°¨   1ë…„ ì „  1055\n",
       "2                                              ì•¼êµ¬ì¥ ì¹˜ì–´ë¦¬ë”   1ë…„ ì „   823\n",
       "3                                                 AV ë°°ìš°   1ë…„ ì „   627\n",
       "4                                      ì„ìƒì‹¤í—˜ ì•Œë°” í•´ì£¼ì„¸ìš”!!!!   1ë…„ ì „   223\n",
       "...                                                 ...    ...   ...\n",
       "3679                                       ì•„ë‚˜ìš´ì„œì˜€ì˜¤ ë¯¸ì¹œã…‹ã…‹ã…‹  6ê°œì›” ì „     0\n",
       "3680                        ë˜˜ë¼ ì©Œë„¤ìš” ã…‹\\ní¸ì§‘ì ì´ ì´ë ‡ê²Œ ë‚˜ì˜¤ê²Œ í•˜ëŠ”ê±´ì§€  6ê°œì›” ì „     1\n",
       "3681          ì•„ì¹¨ë§ˆë‹¤ ë‚ ì”¨ë¡œ ëµ™ëŠ”ë¶„ì¸ë° ì´ë ‡ê²Œ ì›ƒê¸°ì‹  ë¶„ì¼ì¤„ì´ì–”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹  6ê°œì›” ì „     0\n",
       "3682                                       ì €ìŠ¬ ì­ˆë¬¼ëŸ¬ìš¬ã…‹ã…‹ã…‹ã…‹ã…‹  6ê°œì›” ì „     0\n",
       "3683                                      ì´ëˆ„ë‚˜ ã„¹ã…‡ ì·¨ì €ë„¤ã…‹ã…‹ã…‹  6ê°œì›” ì „     0\n",
       "\n",
       "[10409 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encodingì€ ë³´í†µ utf-8, cp949 ë¡œ í•˜ë©´ë˜ì§€ë§Œ ì´ë²ˆ íŒŒì¼ì€ latin1\n",
    "data = pd.read_csv('1.3ë§Œ_ì›Œí¬ë§¨_m8JrVquHNsY.csv', header = None, names = ['review','date','like'])\n",
    "data2 = pd.read_csv('1.6ë§Œ_ì›Œí¬ë§¨_UQYCWLrCUy4.csv', header = None, names = ['review','date','like'])\n",
    "data3 = pd.read_csv('2.4ë§Œ_ì›Œí¬ë§¨_BWROdI-AgAU.csv', header = None, names = ['review','date','like'])\n",
    "\n",
    "data_all = pd.concat([data,data2,data3])\n",
    "\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10409 entries, 0 to 3683\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  10409 non-null  object\n",
      " 1   date    10409 non-null  object\n",
      " 2   like    10409 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 325.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1ë…„ ì „', '1ë…„ ì „(ìˆ˜ì •ë¨)', '10ê°œì›” ì „', '9ê°œì›” ì „', '8ê°œì›” ì „', '7ê°œì›” ì „', '6ê°œì›” ì „',\n",
       "       '4ê°œì›” ì „', '4ê°œì›” ì „(ìˆ˜ì •ë¨)', '3ê°œì›” ì „', '2ê°œì›” ì „', '5ê°œì›” ì „(ìˆ˜ì •ë¨)', '2ì£¼ ì „',\n",
       "       '1ì£¼ ì „', '1ê°œì›” ì „', '4ì£¼ ì „', '9ê°œì›” ì „(ìˆ˜ì •ë¨)', '3ì£¼ ì „', '3ì£¼ ì „(ìˆ˜ì •ë¨)', '4ì¼ ì „',\n",
       "       '34ë¶„ ì „', '30ë¶„ ì „', '5ê°œì›” ì „', '8ê°œì›” ì „(ìˆ˜ì •ë¨)', '3ì‹œê°„ ì „', '11ê°œì›” ì „',\n",
       "       '7ê°œì›” ì „(ìˆ˜ì •ë¨)', '14ì‹œê°„ ì „', '11ê°œì›” ì „(ìˆ˜ì •ë¨)', '1ê°œì›” ì „(ìˆ˜ì •ë¨)', '3ê°œì›” ì „(ìˆ˜ì •ë¨)',\n",
       "       '9ì‹œê°„ ì „', '2ì¼ ì „', '10ê°œì›” ì „(ìˆ˜ì •ë¨)', '6ê°œì›” ì „(ìˆ˜ì •ë¨)', '3ì¼ ì „', '2ê°œì›” ì „(ìˆ˜ì •ë¨)',\n",
       "       '1ì¼ ì „', '6ì¼ ì „', '5ì¼ ì „', '16ì‹œê°„ ì „', '1ì£¼ ì „(ìˆ˜ì •ë¨)', '7ì‹œê°„ ì „',\n",
       "       '2ì£¼ ì „(ìˆ˜ì •ë¨)', '10ì‹œê°„ ì „', '8ì‹œê°„ ì „', '13ì‹œê°„ ì „', '2ì‹œê°„ ì „', '4ì¼ ì „(ìˆ˜ì •ë¨)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.15621097127486"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.15621097127486\n"
     ]
    }
   ],
   "source": [
    "Mean = data_all['like'].mean()\n",
    "print(Mean)\n",
    "\n",
    "data_all.loc[data_all[\"like\"] < Mean, \"like\"] = 0\n",
    "data_all.loc[data_all[\"like\"] >= Mean, \"like\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9515\n",
       "1     894\n",
       "Name: like, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ğŸœğŸœì›Œí¬ë§¨ ì¸ë ¥ì†ŒğŸœğŸœ\\r\\nì›Œí¬ë§¨ì˜ ë¦¬ë·°ë¥¼ ì›í•˜ëŠ” jobê²ƒì´ ìˆë‹¤ë©´â†“ëŒ“ê¸€ ì¶”ì²œâ†“\\r...\n",
       "1                                                   ì¿ íŒ¡ìƒí•˜ì°¨\n",
       "2                                                ì•¼êµ¬ì¥ ì¹˜ì–´ë¦¬ë”\n",
       "3                                                   AV ë°°ìš°\n",
       "4                                        ì„ìƒì‹¤í—˜ ì•Œë°” í•´ì£¼ì„¸ìš”!!!!\n",
       "                              ...                        \n",
       "3679                                         ì•„ë‚˜ìš´ì„œì˜€ì˜¤ ë¯¸ì¹œã…‹ã…‹ã…‹\n",
       "3680                          ë˜˜ë¼ ì©Œë„¤ìš” ã…‹\\ní¸ì§‘ì ì´ ì´ë ‡ê²Œ ë‚˜ì˜¤ê²Œ í•˜ëŠ”ê±´ì§€\n",
       "3681            ì•„ì¹¨ë§ˆë‹¤ ë‚ ì”¨ë¡œ ëµ™ëŠ”ë¶„ì¸ë° ì´ë ‡ê²Œ ì›ƒê¸°ì‹  ë¶„ì¼ì¤„ì´ì–”ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\n",
       "3682                                         ì €ìŠ¬ ì­ˆë¬¼ëŸ¬ìš¬ã…‹ã…‹ã…‹ã…‹ã…‹\n",
       "3683                                        ì´ëˆ„ë‚˜ ã„¹ã…‡ ì·¨ì €ë„¤ã…‹ã…‹ã…‹\n",
       "Name: review, Length: 10409, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['review'] = data_all['review'].str.replace(\"[^\\w]\", \" \")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[0-9]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[a-z]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[A-Z]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.strip()\n",
    "data_all['review'] = data_all['review'].replace('', np.nan)\n",
    "data_all = data_all.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-5c6af552bb78>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"[^\\w]\", \" \")\n",
      "<ipython-input-69-5c6af552bb78>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"ì „\", \"\")\n",
      "<ipython-input-69-5c6af552bb78>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"ê°œ\", \"\")\n",
      "<ipython-input-69-5c6af552bb78>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "data_all['date'] = data_all['date'].str.replace(\"[^\\w]\", \" \")\n",
    "data_all['date'] = data_all['date'].str.replace(\"ì „\", \"\")\n",
    "data_all['date'] = data_all['date'].str.replace(\"ê°œ\", \"\")\n",
    "data_all['date'] = data_all['date'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all['review']=data_all[['review','date']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8968\n",
       "1     866\n",
       "Name: like, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "review_train, review_test,date_train, date_test, y_train, y_test = train_test_split(data_all['review'],data_all['date'], data_all['like'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "stopwords = ['ì´', 'ê°€', 'ì„', 'ë¥¼','ì€','ëŠ”','ì—','ì˜','ë„']\n",
    "\n",
    "cnt = 0\n",
    "X_train = []\n",
    "for stc in review_train:\n",
    "    words = Okt().morphs(stc)\n",
    "    token = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_train.append(token)\n",
    "    \n",
    "X_test = []\n",
    "for stc in review_test:\n",
    "    words = Okt().morphs(stc)\n",
    "    token = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_test.append(token)    \n",
    "    \n",
    "X_train_2 = []\n",
    "for stc in date_train:\n",
    "    X_train_2 = stc.split()\n",
    "    \n",
    "X_test_2 = []\n",
    "for stc in date_test:\n",
    "    X_test_2 = stc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,   27,  531,  436,   27,  417, 1609,   72,\n",
       "        2358,   70,  206,  482,  531,  833, 2359, 2360,  512,  990,   47,\n",
       "        2361,  455,   72,    7, 1345, 3116,  675,  628, 3117,  235,  455,\n",
       "          72,    7,   27,  834,  417, 3118,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,  456,  142,  197,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  991, 1610,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0, 3119,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0, 1192,    3,   29,    1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1230,\n",
       "        3407,  621, 1694,  444,  491,  444,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  284,\n",
       "         621, 1149,  210,   46,  115, 1080,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         110, 1080,  350,  142, 3715, 1363,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,  334,  477,  412,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  430,   47,  632,   76,    2]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_2 = []\n",
    "# for stc in date_train:\n",
    "#     X_train_2.append(stc.split())\n",
    "    \n",
    "# X_test_2 = []\n",
    "# for stc in date_test:\n",
    "#     X_test_2.append(stc.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# X_train ë‹¨ì–´ë“¤ì„ í† ëŒ€ë¡œ ì •ìˆ˜ ì¸ë±ìŠ¤ ì„¤ì •\n",
    "# ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ê²ƒë¶€í„° 4000ê°œë§Œ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ê² ë‹¤!\n",
    "tokenizer = Tokenizer(4000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# ìœ„ì—ì„œ ì„¤ì •ëœ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ í† ëŒ€ë¡œ ë³€í™˜\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "print('# int_encoding done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_2 = Tokenizer()\n",
    "# tokenizer_2.fit_on_texts(X_train_2)\n",
    "\n",
    "# X_train_2 = tokenizer_2.texts_to_sequences(X_train_2)\n",
    "# X_test_2 = tokenizer_2.texts_to_sequences(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13138\n",
      "8319\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.word_index))\n",
    "\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "    if word_count == 1:\n",
    "        low_count += 1\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for data in X_train:\n",
    "    if max_length < len(data):\n",
    "        max_length = len(data)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 40\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "# X_train_2 = pad_sequences(X_train_2, maxlen=2)\n",
    "# X_test_2 = pad_sequences(X_test_2, maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train : np.concatenate((X_train_2,X_train), axis=1)\n",
    "# X_test : np.concatenate((X_test_2,X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(4000, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜¹ì‹œ 5íšŒ ì´ìƒ ê²€ì¦ë°ì´í„° lossê°€ ì¦ê°€í•˜ë©´, ê³¼ì í•©ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•™ìŠµì„ ì¡°ê¸°ì¢…ë£Œ!\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# í›ˆë ¨ì„ ê±°ë“­í•˜ë©´ì„œ, ê°€ì¥ ê²€ì¦ë°ì´í„° ì •í™•ë„ê°€ ë†’ì•˜ë˜ ìˆœê°„ì„ ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥\n",
    "model_check = ModelCheckpoint('the_best.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246/246 [==============================] - 2s 9ms/step - loss: 0.2556 - acc: 0.9166 - val_loss: 0.2664 - val_acc: 0.8937\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1999 - acc: 0.9265 - val_loss: 0.2330 - val_acc: 0.9024\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1842 - acc: 0.9339 - val_loss: 0.2746 - val_acc: 0.9034\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1720 - acc: 0.9364 - val_loss: 0.2670 - val_acc: 0.9024\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1612 - acc: 0.9413 - val_loss: 0.2981 - val_acc: 0.9004\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1521 - acc: 0.9456 - val_loss: 0.3019 - val_acc: 0.8993\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1456 - acc: 0.9481 - val_loss: 0.3210 - val_acc: 0.9029\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1370 - acc: 0.9521 - val_loss: 0.3485 - val_acc: 0.8983\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1278 - acc: 0.9559 - val_loss: 0.3964 - val_acc: 0.8968\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1213 - acc: 0.9593 - val_loss: 0.3546 - val_acc: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225d533b3d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3546 - acc: 0.8953\n",
      "[0.3546484708786011, 0.8952720165252686]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d3150f6b00a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ff\n"
     ]
    }
   ],
   "source": [
    "# ì •í™•ë„ ì¸¡ì •\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "sentence = input()\n",
    "date = input()\n",
    "\n",
    "# í† í°í™”\n",
    "sentence = sentence.replace(\"[^\\w]\", \" \")\n",
    "sentence = sentence.replace(\"[0-9]\", \"\")\n",
    "sentence = sentence.replace(\"[a-z]\", \"\")\n",
    "sentence = sentence.replace(\"[A-Z]\", \"\")\n",
    "sentence = sentence.strip()\n",
    "\n",
    "date = date.replace(\"[^\\w]\", \" \")\n",
    "date = date.replace(\"ì „\", \"\")\n",
    "date = date.replace(\"ê°œ\", \"\")\n",
    "date = date.strip()\n",
    "\n",
    "sentence+=date\n",
    "\n",
    "words = Okt().morphs(sentence)\n",
    "\n",
    "words_re = []\n",
    "for word in words:\n",
    "    if word not in stopwords:\n",
    "        words_re.append(word)\n",
    "\n",
    "encode_stc = tokenizer.texts_to_sequences([words_re])\n",
    "\n",
    "pad_stc = pad_sequences(encode_stc, maxlen = 40)\n",
    "print(pad_stc)\n",
    "print(model.predict(pad_stc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
