{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🐜🐜워크맨 인력소🐜🐜\\r\\n워크맨의 리뷰를 원하는 job것이 있다면↓댓글 추천↓\\r...</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>7101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쿠팡상하차</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>야구장 치어리더</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV 배우</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임상실험 알바 해주세요!!!!</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>아나운서였오 미친ㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>똘끼 쩌네요 ㅋ\\n편집점이 이렇게 나오게 하는건지</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>아침마다 날씨로 뵙는분인데 이렇게 웃기신 분일줄이얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>저슬 쭈물러욬ㅋㅋㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>이누나 ㄹㅇ 취저네ㅋㅋㅋ</td>\n",
       "      <td>6개월 전</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10409 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review   date  like\n",
       "0     🐜🐜워크맨 인력소🐜🐜\\r\\n워크맨의 리뷰를 원하는 job것이 있다면↓댓글 추천↓\\r...   1년 전  7101\n",
       "1                                                 쿠팡상하차   1년 전  1055\n",
       "2                                              야구장 치어리더   1년 전   823\n",
       "3                                                 AV 배우   1년 전   627\n",
       "4                                      임상실험 알바 해주세요!!!!   1년 전   223\n",
       "...                                                 ...    ...   ...\n",
       "3679                                       아나운서였오 미친ㅋㅋㅋ  6개월 전     0\n",
       "3680                        똘끼 쩌네요 ㅋ\\n편집점이 이렇게 나오게 하는건지  6개월 전     1\n",
       "3681          아침마다 날씨로 뵙는분인데 이렇게 웃기신 분일줄이얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ  6개월 전     0\n",
       "3682                                       저슬 쭈물러욬ㅋㅋㅋㅋㅋ  6개월 전     0\n",
       "3683                                      이누나 ㄹㅇ 취저네ㅋㅋㅋ  6개월 전     0\n",
       "\n",
       "[10409 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding은 보통 utf-8, cp949 로 하면되지만 이번 파일은 latin1\n",
    "data = pd.read_csv('1.3만_워크맨_m8JrVquHNsY.csv', header = None, names = ['review','date','like'])\n",
    "data2 = pd.read_csv('1.6만_워크맨_UQYCWLrCUy4.csv', header = None, names = ['review','date','like'])\n",
    "data3 = pd.read_csv('2.4만_워크맨_BWROdI-AgAU.csv', header = None, names = ['review','date','like'])\n",
    "\n",
    "data_all = pd.concat([data,data2,data3])\n",
    "\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10409 entries, 0 to 3683\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  10409 non-null  object\n",
      " 1   date    10409 non-null  object\n",
      " 2   like    10409 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 325.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1년 전', '1년 전(수정됨)', '10개월 전', '9개월 전', '8개월 전', '7개월 전', '6개월 전',\n",
       "       '4개월 전', '4개월 전(수정됨)', '3개월 전', '2개월 전', '5개월 전(수정됨)', '2주 전',\n",
       "       '1주 전', '1개월 전', '4주 전', '9개월 전(수정됨)', '3주 전', '3주 전(수정됨)', '4일 전',\n",
       "       '34분 전', '30분 전', '5개월 전', '8개월 전(수정됨)', '3시간 전', '11개월 전',\n",
       "       '7개월 전(수정됨)', '14시간 전', '11개월 전(수정됨)', '1개월 전(수정됨)', '3개월 전(수정됨)',\n",
       "       '9시간 전', '2일 전', '10개월 전(수정됨)', '6개월 전(수정됨)', '3일 전', '2개월 전(수정됨)',\n",
       "       '1일 전', '6일 전', '5일 전', '16시간 전', '1주 전(수정됨)', '7시간 전',\n",
       "       '2주 전(수정됨)', '10시간 전', '8시간 전', '13시간 전', '2시간 전', '4일 전(수정됨)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.15621097127486"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.15621097127486\n"
     ]
    }
   ],
   "source": [
    "Mean = data_all['like'].mean()\n",
    "print(Mean)\n",
    "\n",
    "data_all.loc[data_all[\"like\"] < Mean, \"like\"] = 0\n",
    "data_all.loc[data_all[\"like\"] >= Mean, \"like\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9515\n",
       "1     894\n",
       "Name: like, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       🐜🐜워크맨 인력소🐜🐜\\r\\n워크맨의 리뷰를 원하는 job것이 있다면↓댓글 추천↓\\r...\n",
       "1                                                   쿠팡상하차\n",
       "2                                                야구장 치어리더\n",
       "3                                                   AV 배우\n",
       "4                                        임상실험 알바 해주세요!!!!\n",
       "                              ...                        \n",
       "3679                                         아나운서였오 미친ㅋㅋㅋ\n",
       "3680                          똘끼 쩌네요 ㅋ\\n편집점이 이렇게 나오게 하는건지\n",
       "3681            아침마다 날씨로 뵙는분인데 이렇게 웃기신 분일줄이얔ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
       "3682                                         저슬 쭈물러욬ㅋㅋㅋㅋㅋ\n",
       "3683                                        이누나 ㄹㅇ 취저네ㅋㅋㅋ\n",
       "Name: review, Length: 10409, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['review'] = data_all['review'].str.replace(\"[^\\w]\", \" \")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[0-9]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[a-z]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.replace(\"[A-Z]\", \"\")\n",
    "data_all['review'] = data_all['review'].str.strip()\n",
    "data_all['review'] = data_all['review'].replace('', np.nan)\n",
    "data_all = data_all.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-5c6af552bb78>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"[^\\w]\", \" \")\n",
      "<ipython-input-69-5c6af552bb78>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"전\", \"\")\n",
      "<ipython-input-69-5c6af552bb78>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.replace(\"개\", \"\")\n",
      "<ipython-input-69-5c6af552bb78>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_all['date'] = data_all['date'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "data_all['date'] = data_all['date'].str.replace(\"[^\\w]\", \" \")\n",
    "data_all['date'] = data_all['date'].str.replace(\"전\", \"\")\n",
    "data_all['date'] = data_all['date'].str.replace(\"개\", \"\")\n",
    "data_all['date'] = data_all['date'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all['review']=data_all[['review','date']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8968\n",
       "1     866\n",
       "Name: like, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['like'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "review_train, review_test,date_train, date_test, y_train, y_test = train_test_split(data_all['review'],data_all['date'], data_all['like'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "stopwords = ['이', '가', '을', '를','은','는','에','의','도']\n",
    "\n",
    "cnt = 0\n",
    "X_train = []\n",
    "for stc in review_train:\n",
    "    words = Okt().morphs(stc)\n",
    "    token = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_train.append(token)\n",
    "    \n",
    "X_test = []\n",
    "for stc in review_test:\n",
    "    words = Okt().morphs(stc)\n",
    "    token = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_test.append(token)    \n",
    "    \n",
    "X_train_2 = []\n",
    "for stc in date_train:\n",
    "    X_train_2 = stc.split()\n",
    "    \n",
    "X_test_2 = []\n",
    "for stc in date_test:\n",
    "    X_test_2 = stc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,   27,  531,  436,   27,  417, 1609,   72,\n",
       "        2358,   70,  206,  482,  531,  833, 2359, 2360,  512,  990,   47,\n",
       "        2361,  455,   72,    7, 1345, 3116,  675,  628, 3117,  235,  455,\n",
       "          72,    7,   27,  834,  417, 3118,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,  456,  142,  197,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  991, 1610,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0, 3119,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0, 1192,    3,   29,    1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1230,\n",
       "        3407,  621, 1694,  444,  491,  444,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  284,\n",
       "         621, 1149,  210,   46,  115, 1080,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         110, 1080,  350,  142, 3715, 1363,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,  334,  477,  412,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  430,   47,  632,   76,    2]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_2 = []\n",
    "# for stc in date_train:\n",
    "#     X_train_2.append(stc.split())\n",
    "    \n",
    "# X_test_2 = []\n",
    "# for stc in date_test:\n",
    "#     X_test_2.append(stc.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# X_train 단어들을 토대로 정수 인덱스 설정\n",
    "# 빈도수가 높은 것부터 4000개만 정수 인덱스로 변환하겠다!\n",
    "tokenizer = Tokenizer(4000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 위에서 설정된 정수 인덱스를 토대로 변환\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "print('# int_encoding done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_2 = Tokenizer()\n",
    "# tokenizer_2.fit_on_texts(X_train_2)\n",
    "\n",
    "# X_train_2 = tokenizer_2.texts_to_sequences(X_train_2)\n",
    "# X_test_2 = tokenizer_2.texts_to_sequences(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13138\n",
      "8319\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.word_index))\n",
    "\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "    if word_count == 1:\n",
    "        low_count += 1\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for data in X_train:\n",
    "    if max_length < len(data):\n",
    "        max_length = len(data)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 40\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "# X_train_2 = pad_sequences(X_train_2, maxlen=2)\n",
    "# X_test_2 = pad_sequences(X_test_2, maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train : np.concatenate((X_train_2,X_train), axis=1)\n",
    "# X_test : np.concatenate((X_test_2,X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(4000, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 5회 이상 검증데이터 loss가 증가하면, 과적합될 수 있으므로 학습을 조기종료!\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# 훈련을 거듭하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트로 저장\n",
    "model_check = ModelCheckpoint('the_best.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "246/246 [==============================] - 2s 9ms/step - loss: 0.2556 - acc: 0.9166 - val_loss: 0.2664 - val_acc: 0.8937\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1999 - acc: 0.9265 - val_loss: 0.2330 - val_acc: 0.9024\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1842 - acc: 0.9339 - val_loss: 0.2746 - val_acc: 0.9034\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1720 - acc: 0.9364 - val_loss: 0.2670 - val_acc: 0.9024\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1612 - acc: 0.9413 - val_loss: 0.2981 - val_acc: 0.9004\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1521 - acc: 0.9456 - val_loss: 0.3019 - val_acc: 0.8993\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 2s 8ms/step - loss: 0.1456 - acc: 0.9481 - val_loss: 0.3210 - val_acc: 0.9029\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1370 - acc: 0.9521 - val_loss: 0.3485 - val_acc: 0.8983\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1278 - acc: 0.9559 - val_loss: 0.3964 - val_acc: 0.8968\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 2s 7ms/step - loss: 0.1213 - acc: 0.9593 - val_loss: 0.3546 - val_acc: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225d533b3d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3546 - acc: 0.8953\n",
      "[0.3546484708786011, 0.8952720165252686]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d3150f6b00a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ff\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "sentence = input()\n",
    "date = input()\n",
    "\n",
    "# 토큰화\n",
    "sentence = sentence.replace(\"[^\\w]\", \" \")\n",
    "sentence = sentence.replace(\"[0-9]\", \"\")\n",
    "sentence = sentence.replace(\"[a-z]\", \"\")\n",
    "sentence = sentence.replace(\"[A-Z]\", \"\")\n",
    "sentence = sentence.strip()\n",
    "\n",
    "date = date.replace(\"[^\\w]\", \" \")\n",
    "date = date.replace(\"전\", \"\")\n",
    "date = date.replace(\"개\", \"\")\n",
    "date = date.strip()\n",
    "\n",
    "sentence+=date\n",
    "\n",
    "words = Okt().morphs(sentence)\n",
    "\n",
    "words_re = []\n",
    "for word in words:\n",
    "    if word not in stopwords:\n",
    "        words_re.append(word)\n",
    "\n",
    "encode_stc = tokenizer.texts_to_sequences([words_re])\n",
    "\n",
    "pad_stc = pad_sequences(encode_stc, maxlen = 40)\n",
    "print(pad_stc)\n",
    "print(model.predict(pad_stc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
